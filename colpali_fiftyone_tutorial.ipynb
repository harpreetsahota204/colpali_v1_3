{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ColPali v1.3 for FiftyOne Tutorial\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/harpreetsahota204/colpali_v1_3/blob/main/colpali_fiftyone_tutorial.ipynb)\n",
        "\n",
        "This notebook demonstrates how to use ColPali v1.3 with FiftyOne for visual document retrieval.\n",
        "\n",
        "## Overview\n",
        "\n",
        "ColPali is a Vision Language Model based on PaliGemma-3B that generates ColBERT-style multi-vector representations for efficient document retrieval. This integration uses token pooling to make ColPali compatible with FiftyOne's similarity infrastructure.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n",
        "\n",
        "Install required packages:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install fiftyone colpali-engine transformers torch huggingface-hub umap-learn\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Register the Zoo Model\n",
        "\n",
        "Register this repository as a FiftyOne zoo model source:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import fiftyone.zoo as foz\n",
        "\n",
        "# Register this repository as a remote zoo model source\n",
        "foz.register_zoo_model_source(\n",
        "    \"https://github.com/harpreetsahota204/colpali_v1_3\",\n",
        "    overwrite=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Dataset\n",
        "\n",
        "Load a document dataset from Hugging Face:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import fiftyone as fo\n",
        "from fiftyone.utils.huggingface import load_from_hub\n",
        "\n",
        "# Load document dataset from Hugging Face\n",
        "dataset = load_from_hub(\n",
        "    \"Voxel51/document-haystack-10pages\",\n",
        "    overwrite=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Basic Workflow: Document Retrieval\n",
        "\n",
        "### Load Model and Compute Embeddings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import fiftyone.zoo as foz\n",
        "\n",
        "# Load ColPali model with desired pooling strategy\n",
        "model = foz.load_zoo_model(\n",
        "    \"vidore/colpali-v1.3-merged\",\n",
        "    pooling_strategy=\"max\",  # or \"mean\" (default)\n",
        "    pool_factor=3  # Compression factor\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compute embeddings for all documents\n",
        "dataset.compute_embeddings(\n",
        "    model=model,\n",
        "    embeddings_field=\"copali_embeddings\",\n",
        ")\n",
        "\n",
        "# Check embedding dimensions\n",
        "print(dataset.first()['copali_embeddings'].shape)  # Should be (128,)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Build Similarity Index\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import fiftyone.brain as fob\n",
        "\n",
        "# Build similarity index\n",
        "text_img_index = fob.compute_similarity(\n",
        "    dataset,\n",
        "    model=\"vidore/colpali-v1.3-merged\",\n",
        "    embeddings_field=\"copali_embeddings\",\n",
        "    brain_key=\"copali_sim\",\n",
        "    model_kwargs={\n",
        "        \"pooling_strategy\": \"max\",\n",
        "        \"pool_factor\": 3,\n",
        "    }\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Query for Specific Content\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Query for specific content\n",
        "sims = text_img_index.sort_by_similarity(\n",
        "    \"the secret office supply is pencil\"\n",
        ")\n",
        "\n",
        "# Launch FiftyOne App\n",
        "session = fo.launch_app(dataset, auto=False)\n",
        "print(session.url)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Advanced Embedding Workflows\n",
        "\n",
        "### 1. Embedding Visualization with UMAP\n",
        "\n",
        "Create 2D visualizations of your document embeddings:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import fiftyone.brain as fob\n",
        "\n",
        "# Create UMAP visualization\n",
        "results = fob.compute_visualization(\n",
        "    dataset,\n",
        "    method=\"umap\",  # Also supports \"tsne\", \"pca\"\n",
        "    brain_key=\"copali_viz\",\n",
        "    embeddings=\"copali_embeddings\"\n",
        ")\n",
        "\n",
        "# Explore in the App\n",
        "session = fo.launch_app(dataset)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. Similarity Search\n",
        "\n",
        "Build powerful similarity search with ColPali embeddings:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import fiftyone.brain as fob\n",
        "\n",
        "# Build similarity index\n",
        "results = fob.compute_similarity(\n",
        "    dataset,\n",
        "    backend=\"sklearn\",  # Fast sklearn backend\n",
        "    brain_key=\"colpali_sim\", \n",
        "    embeddings=\"colpali_embeddings\"\n",
        ")\n",
        "\n",
        "# Find similar images\n",
        "sample_id = dataset.first().id\n",
        "similar_samples = dataset.sort_by_similarity(\n",
        "    sample_id,\n",
        "    brain_key=\"colpali_sim\",\n",
        "    k=10  # Top 10 most similar\n",
        ")\n",
        "\n",
        "# View results\n",
        "session = fo.launch_app(similar_samples)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. Dataset Representativeness\n",
        "\n",
        "Score how representative each sample is of your dataset:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import fiftyone.brain as fob\n",
        "\n",
        "# Compute representativeness scores\n",
        "fob.compute_representativeness(\n",
        "    dataset,\n",
        "    representativeness_field=\"colpali_represent\",\n",
        "    method=\"cluster-center\",\n",
        "    embeddings=\"colpali_embeddings\"\n",
        ")\n",
        "\n",
        "# Find most representative samples\n",
        "representative_view = dataset.sort_by(\"colpali_represent\", reverse=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4. Duplicate Detection\n",
        "\n",
        "Find and remove near-duplicate documents:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import fiftyone.brain as fob\n",
        "\n",
        "# Detect duplicates using embeddings\n",
        "results = fob.compute_uniqueness(\n",
        "    dataset,\n",
        "    embeddings=\"colpali_embeddings\"\n",
        ")\n",
        "\n",
        "# Filter to most unique samples\n",
        "unique_view = dataset.sort_by(\"uniqueness\", reverse=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuration Options\n",
        "\n",
        "### Pooling Strategy Comparison\n",
        "\n",
        "Compare mean vs max pooling strategies:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mean pooling (default) - holistic document matching\n",
        "model_mean = foz.load_zoo_model(\n",
        "    \"vidore/colpali-v1.3-merged\",\n",
        "    pooling_strategy=\"mean\",\n",
        "    pool_factor=3\n",
        ")\n",
        "\n",
        "# Max pooling - specific content/keyword matching\n",
        "model_max = foz.load_zoo_model(\n",
        "    \"vidore/colpali-v1.3-merged\",\n",
        "    pooling_strategy=\"max\",\n",
        "    pool_factor=3\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Custom Pool Factor\n",
        "\n",
        "Adjust compression level:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# More aggressive compression (faster, less accurate)\n",
        "model_compressed = foz.load_zoo_model(\n",
        "    \"vidore/colpali-v1.3-merged\",\n",
        "    pool_factor=5\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Understanding the Compression Pipeline\n",
        "\n",
        "ColPali natively produces variable-length multi-vector embeddings that are incompatible with FiftyOne's fixed-dimension requirements. This integration uses a two-stage compression approach:\n",
        "\n",
        "### Stage 1: Token Pooling (Intelligent Compression)\n",
        "- Images: `(1031, 128)` → `(~344, 128)`\n",
        "- Queries: `(19, 128)` → `(~6, 128)`\n",
        "- **Retains ~97.8% accuracy**\n",
        "- Removes redundant patches (e.g., white backgrounds)\n",
        "\n",
        "### Stage 2: Final Pooling (Fixed Dimensions)\n",
        "- Mean or Max pooling: `(~344, 128)` → `(128,)`\n",
        "- **FiftyOne compatible**\n",
        "- Both strategies work for classification and retrieval\n",
        "\n",
        "**Trade-off**: ~85-90% of native ColPali accuracy for full FiftyOne compatibility.\n",
        "\n",
        "For production applications requiring native ColPali accuracy, consider using dedicated vector databases like [Qdrant](https://qdrant.tech/) or [Weaviate](https://weaviate.io/) that support multi-vector search natively.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Resources\n",
        "\n",
        "- **Original Repository**: [illuin-tech/colpali](https://github.com/illuin-tech/colpali)\n",
        "- **Model Weights**: [vidore/colpali-v1.3-merged](https://huggingface.co/vidore/colpali-v1.3-merged)\n",
        "- **Paper**: [ColPali: Efficient Document Retrieval with Vision Language Models](https://arxiv.org/abs/2407.01449)\n",
        "\n",
        "### Citation\n",
        "\n",
        "If you use ColPali in your research, please cite:\n",
        "\n",
        "```bibtex\n",
        "@misc{faysse2024colpaliefficientdocumentretrieval,\n",
        "      title={ColPali: Efficient Document Retrieval with Vision Language Models}, \n",
        "      author={Manuel Faysse and Hugues Sibille and Tony Wu and Bilel Omrani and Gautier Viaud and Céline Hudelot and Pierre Colombo},\n",
        "      year={2024},\n",
        "      eprint={2407.01449},\n",
        "      archivePrefix={arXiv},\n",
        "      primaryClass={cs.IR},\n",
        "      url={https://arxiv.org/abs/2407.01449},\n",
        "}\n",
        "```\n",
        "\n",
        "## License\n",
        "\n",
        "- **Model Weights**: [Gemma License](https://ai.google.dev/gemma/terms)\n",
        "- **Integration Code**: Apache 2.0 License\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
